{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.autograd import Variable   # to build a computational graph\n",
    "import torch.nn as nn                 # neural net library (with layers and cost functions)\n",
    "import torch.nn.functional as F       # contains autograd-compliant functions  \n",
    "import torch.optim as optim           # to easily build an optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model with single hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):   \n",
    "        \"\"\"Initialize the layers of the model.\"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,32)  # Applies a linear transformation to the incoming data: y=Ax+b\n",
    "        self.fc2 = nn.Linear(32,1)\n",
    "     \n",
    "    def forward(self,x):\n",
    "        \"\"\"Defines model structure;\n",
    "        receives tensor containing input,  \n",
    "        and returns output tensor.\"\"\"\n",
    "        x = F.sigmoid(self.fc1(x))   #Applies the element-wise function f(x)=1/(1+exp(âˆ’x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "\n",
    "# Train_data\n",
    "predictors = list(map(lambda s: Variable(torch.Tensor([s])), [[0,0], [0,1], [1,0], [1,1]]))\n",
    "targets = list(map(lambda s: Variable(torch.Tensor([s])), [[0], [1], [1], [0]]))\n",
    "\n",
    "# Loss and Optimization\n",
    "criterion = nn.MSELoss()                            # Use mean squared error loss\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)   # Adam updates the learning rate\n",
    "\n",
    "nepochs = 2000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 loss: 0.22060208022594452\n",
      "Epoch: 100 loss: 0.25921428203582764\n",
      "Epoch: 100 loss: 0.23687328398227692\n",
      "Epoch: 100 loss: 0.2816235423088074\n",
      "Epoch: 200 loss: 0.06460932642221451\n",
      "Epoch: 200 loss: 0.1621261090040207\n",
      "Epoch: 200 loss: 0.09519004821777344\n",
      "Epoch: 200 loss: 0.20577968657016754\n",
      "Epoch: 300 loss: 0.0014266553334891796\n",
      "Epoch: 300 loss: 0.0039820135571062565\n",
      "Epoch: 300 loss: 0.0022835356649011374\n",
      "Epoch: 300 loss: 0.005284433253109455\n",
      "Epoch: 400 loss: 5.691996989298787e-07\n",
      "Epoch: 400 loss: 1.5177461136772763e-06\n",
      "Epoch: 400 loss: 9.008750225802942e-07\n",
      "Epoch: 400 loss: 2.017919996433193e-06\n",
      "Epoch: 500 loss: 1.0844880549143454e-11\n",
      "Epoch: 500 loss: 2.689048983484099e-11\n",
      "Epoch: 500 loss: 1.6427748050773516e-11\n",
      "Epoch: 500 loss: 3.561601014112625e-11\n",
      "Epoch: 600 loss: 4.105604745063829e-13\n",
      "Epoch: 600 loss: 6.963318810448982e-13\n",
      "Epoch: 600 loss: 6.004086117172847e-13\n",
      "Epoch: 600 loss: 9.094947017729282e-13\n",
      "Epoch: 700 loss: 1.5593082380860324e-13\n",
      "Epoch: 700 loss: 3.552713678800501e-13\n",
      "Epoch: 700 loss: 2.2737367544323206e-13\n",
      "Epoch: 700 loss: 6.004086117172847e-13\n",
      "Epoch: 800 loss: 1.0746958878371515e-13\n",
      "Epoch: 800 loss: 1.7408297026122455e-13\n",
      "Epoch: 800 loss: 1.2789769243681803e-13\n",
      "Epoch: 800 loss: 2.9581892491137296e-13\n",
      "Epoch: 900 loss: 3.197442310920451e-14\n",
      "Epoch: 900 loss: 1.2789769243681803e-13\n",
      "Epoch: 900 loss: 5.684341886080802e-14\n",
      "Epoch: 900 loss: 1.7408297026122455e-13\n",
      "Epoch: 1000 loss: 3.469446951953614e-14\n",
      "Epoch: 1000 loss: 8.881784197001252e-14\n",
      "Epoch: 1000 loss: 3.197442310920451e-14\n",
      "Epoch: 1000 loss: 1.5010215292932116e-13\n",
      "Epoch: 1100 loss: 9.381384558082573e-15\n",
      "Epoch: 1100 loss: 3.197442310920451e-14\n",
      "Epoch: 1100 loss: 1.4210854715202004e-14\n",
      "Epoch: 1100 loss: 5.334621633323877e-14\n",
      "Epoch: 1200 loss: 4.496403249731884e-15\n",
      "Epoch: 1200 loss: 1.4210854715202004e-14\n",
      "Epoch: 1200 loss: 3.552713678800501e-15\n",
      "Epoch: 1200 loss: 2.4480417692984702e-14\n",
      "Epoch: 1300 loss: 7.993605777301127e-15\n",
      "Epoch: 1300 loss: 3.552713678800501e-15\n",
      "Epoch: 1300 loss: 1.4210854715202004e-14\n",
      "Epoch: 1300 loss: 1.7985612998927536e-14\n",
      "Epoch: 1400 loss: 1.3877787807814457e-15\n",
      "Epoch: 1400 loss: 0.0\n",
      "Epoch: 1400 loss: 0.0\n",
      "Epoch: 1400 loss: 8.881784197001252e-16\n",
      "Epoch: 1500 loss: 5.551115123125783e-17\n",
      "Epoch: 1500 loss: 0.0\n",
      "Epoch: 1500 loss: 0.0\n",
      "Epoch: 1500 loss: 0.0\n",
      "Epoch: 1600 loss: 5.551115123125783e-17\n",
      "Epoch: 1600 loss: 0.0\n",
      "Epoch: 1600 loss: 0.0\n",
      "Epoch: 1600 loss: 0.0\n",
      "Epoch: 1700 loss: 5.551115123125783e-17\n",
      "Epoch: 1700 loss: 0.0\n",
      "Epoch: 1700 loss: 0.0\n",
      "Epoch: 1700 loss: 0.0\n",
      "Epoch: 1800 loss: 5.551115123125783e-17\n",
      "Epoch: 1800 loss: 0.0\n",
      "Epoch: 1800 loss: 0.0\n",
      "Epoch: 1800 loss: 0.0\n",
      "Epoch: 1900 loss: 0.000244848954025656\n",
      "Epoch: 1900 loss: 0.00020507651788648218\n",
      "Epoch: 1900 loss: 8.592850520017237e-08\n",
      "Epoch: 1900 loss: 4.7896790533741296e-08\n",
      "Epoch: 2000 loss: 2.220446049250313e-14\n",
      "Epoch: 2000 loss: 5.684341886080802e-14\n",
      "Epoch: 2000 loss: 1.4210854715202004e-14\n",
      "Epoch: 2000 loss: 2.220446049250313e-14\n",
      "Finished training the network\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, nepochs):\n",
    "    \n",
    "    for i, target in zip(predictors, targets):\n",
    "        \n",
    "        optimizer.zero_grad()   # zero the parameter gradients for each new batch\n",
    "        \n",
    "        # Forward, backward and optimization\n",
    "        y_pred = net(i)\n",
    "        loss = criterion(y_pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print stats\n",
    "        if epoch % 100 == 99:   # print every 100th epoch\n",
    "            print(\"Epoch: {} loss: {}\".format(epoch + 1, loss.data.numpy()))\n",
    "            \n",
    "print('Finished training the network')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "Input:[0,0] Target:[0] Predicted:[0.0] Error:[0.0]\n",
      "Input:[0,1] Target:[1] Predicted:[1.0] Error:[0.0]\n",
      "Input:[1,0] Target:[1] Predicted:[1.0] Error:[0.0]\n",
      "Input:[1,1] Target:[0] Predicted:[0.0] Error:[0.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Results:\")\n",
    "for i, target in zip(predictors, targets):\n",
    "    y_pred = net(i)\n",
    "    print(\"Input:[{},{}] Target:[{}] Predicted:[{}] Error:[{}]\".format(\n",
    "        int(i.data.numpy()[0][0]),\n",
    "        int(i.data.numpy()[0][1]),\n",
    "        int(target.data.numpy()[0]),\n",
    "        round(float(y_pred.data.numpy()[0]), 4),\n",
    "        round(float(abs(target.data.numpy()[0] - y_pred.data.numpy()[0])), 4)\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
